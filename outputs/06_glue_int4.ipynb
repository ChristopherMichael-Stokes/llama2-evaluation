{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c04f5734",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-09T02:42:49.135665Z",
     "iopub.status.busy": "2023-08-09T02:42:49.135527Z",
     "iopub.status.idle": "2023-08-09T02:42:50.682123Z",
     "shell.execute_reply": "2023-08-09T02:42:50.681776Z"
    },
    "papermill": {
     "duration": 1.550677,
     "end_time": "2023-08-09T02:42:50.683200",
     "exception": false,
     "start_time": "2023-08-09T02:42:49.132523",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chris/Desktop/repos/llama2/.env/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from llama2 import *\n",
    "from typing import List, Literal, Optional, Tuple, TypedDict\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datasets\n",
    "import string\n",
    "from evaluate import evaluator\n",
    "from evaluate import load\n",
    "\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "613fae97",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-09T02:42:50.687674Z",
     "iopub.status.busy": "2023-08-09T02:42:50.687508Z",
     "iopub.status.idle": "2023-08-09T02:42:50.689305Z",
     "shell.execute_reply": "2023-08-09T02:42:50.689050Z"
    },
    "papermill": {
     "duration": 0.005017,
     "end_time": "2023-08-09T02:42:50.690102",
     "exception": false,
     "start_time": "2023-08-09T02:42:50.685085",
     "status": "completed"
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "model_size='int4'\n",
    "max_samples=-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "491e5501",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-09T02:42:50.694243Z",
     "iopub.status.busy": "2023-08-09T02:42:50.694118Z",
     "iopub.status.idle": "2023-08-09T02:42:50.695781Z",
     "shell.execute_reply": "2023-08-09T02:42:50.695555Z"
    },
    "papermill": {
     "duration": 0.004902,
     "end_time": "2023-08-09T02:42:50.696586",
     "exception": false,
     "start_time": "2023-08-09T02:42:50.691684",
     "status": "completed"
    },
    "tags": [
     "injected-parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "model_size = \"int4\"\n",
    "max_samples = -1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e59b0835",
   "metadata": {
    "papermill": {
     "duration": 0.001887,
     "end_time": "2023-08-09T02:42:50.700172",
     "exception": false,
     "start_time": "2023-08-09T02:42:50.698285",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 1 - Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24dcea71",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-09T02:42:50.704789Z",
     "iopub.status.busy": "2023-08-09T02:42:50.704661Z",
     "iopub.status.idle": "2023-08-09T02:42:53.390041Z",
     "shell.execute_reply": "2023-08-09T02:42:53.389710Z"
    },
    "papermill": {
     "duration": 2.688831,
     "end_time": "2023-08-09T02:42:53.390899",
     "exception": false,
     "start_time": "2023-08-09T02:42:50.702068",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading checkpoint shards:   0%|                                                        | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading checkpoint shards:  50%|████████████████████████                        | 1/2 [00:01<00:01,  1.07s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading checkpoint shards: 100%|████████████████████████████████████████████████| 2/2 [00:01<00:00,  1.47it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Loading checkpoint shards: 100%|████████████████████████████████████████████████| 2/2 [00:01<00:00,  1.36it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#papermill_description=LOADING_MODEL\n",
    "model_name = \"meta-llama/Llama-2-7b-chat-hf\"\n",
    "\n",
    "model = LlamaModel(\n",
    "    model_name=model_name,\n",
    "    model_resolution=model_size\n",
    ")\n",
    "\n",
    "model.model.to = lambda x: x # Disable device copying"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f05722f",
   "metadata": {
    "papermill": {
     "duration": 0.00208,
     "end_time": "2023-08-09T02:42:53.395334",
     "exception": false,
     "start_time": "2023-08-09T02:42:53.393254",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 2 - Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4182b012",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-09T02:42:53.400360Z",
     "iopub.status.busy": "2023-08-09T02:42:53.400227Z",
     "iopub.status.idle": "2023-08-09T02:42:54.631207Z",
     "shell.execute_reply": "2023-08-09T02:42:54.630873Z"
    },
    "papermill": {
     "duration": 1.234842,
     "end_time": "2023-08-09T02:42:54.632298",
     "exception": false,
     "start_time": "2023-08-09T02:42:53.397456",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#papermill_description=LOADING_DATA\n",
    "dataset = datasets.load_dataset('glue', 'mnli', split='validation_matched')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "430772a6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-09T02:42:54.637480Z",
     "iopub.status.busy": "2023-08-09T02:42:54.637350Z",
     "iopub.status.idle": "2023-08-09T02:42:54.640681Z",
     "shell.execute_reply": "2023-08-09T02:42:54.640463Z"
    },
    "papermill": {
     "duration": 0.006896,
     "end_time": "2023-08-09T02:42:54.641488",
     "exception": false,
     "start_time": "2023-08-09T02:42:54.634592",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['premise', 'hypothesis', 'label', 'idx'],\n",
       "    num_rows: 9815\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8dd1a14a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-09T02:42:54.646433Z",
     "iopub.status.busy": "2023-08-09T02:42:54.646308Z",
     "iopub.status.idle": "2023-08-09T02:42:54.648579Z",
     "shell.execute_reply": "2023-08-09T02:42:54.648366Z"
    },
    "papermill": {
     "duration": 0.00579,
     "end_time": "2023-08-09T02:42:54.649329",
     "exception": false,
     "start_time": "2023-08-09T02:42:54.643539",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'premise': \"well that would be a help i wish they would do that here we have got so little landfill space left that we're going to run out before the end of this decade and it's really going to be\",\n",
       " 'hypothesis': 'We have plenty of space in the landfill.',\n",
       " 'label': 2,\n",
       " 'idx': 5}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b929d4ee",
   "metadata": {
    "papermill": {
     "duration": 0.002315,
     "end_time": "2023-08-09T02:42:54.653805",
     "exception": false,
     "start_time": "2023-08-09T02:42:54.651490",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 3 - Define data prep and model inference functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee0e8c6c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-09T02:42:54.659304Z",
     "iopub.status.busy": "2023-08-09T02:42:54.659179Z",
     "iopub.status.idle": "2023-08-09T02:42:54.662647Z",
     "shell.execute_reply": "2023-08-09T02:42:54.662425Z"
    },
    "papermill": {
     "duration": 0.007179,
     "end_time": "2023-08-09T02:42:54.663347",
     "exception": false,
     "start_time": "2023-08-09T02:42:54.656168",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def format_question(sample: dict) -> str:\n",
    "    \"\"\"Format a sample from the squad V2 dataset to question answer string.\"\"\"\n",
    "    pretext = (f'{model.B_INST} You are performing natural language inference tasks. '\n",
    "               'Given a premise and hypothesis, decide whether we have an entailment, neutral or contradiction relation. '\n",
    "               'Only respond with the words \"The response is \" and one of \"neutral, contradiction, entailment\"'\n",
    "               f' {model.E_INST}\\n')  # Llama system directive\n",
    "    q_a = (f'Premise: {sample[\"premise\"]}\\n'\n",
    "         f'Hypothesis: {sample[\"hypothesis\"]}\\n'\n",
    "         f'Answer: \\n\\nThe response is:')\n",
    "    \n",
    "    return pretext + q_a\n",
    "\n",
    "\n",
    "def glue_inference(df: pd.DataFrame, model) -> pd.DataFrame:\n",
    "    \"\"\"Predict the output extracts for all samples in the input squad format dataset\"\"\"\n",
    "    df_val = df.copy(deep=True)\n",
    "    df['prediction'] = -1\n",
    "    df['prob'] = -1\n",
    "    \n",
    "    labels = ['neutral', 'entailment', 'contradiction']\n",
    "    label_ids = [model.tokenizer.encode(label, add_special_tokens=False)[0] for label in labels]\n",
    "\n",
    "    for idx in range(len(df)):\n",
    "        with torch.no_grad():\n",
    "            x = format_question(df.iloc[idx])\n",
    "            tokens = model.tokenize(x)\n",
    "            logits = model.model(tokens).logits\n",
    "            probs = torch.softmax(logits[:,-1,label_ids], dim=1)\n",
    "            \n",
    "        df_val.loc[idx, 'prediction'] = probs.argmax().item()\n",
    "        df_val.loc[idx, 'prob'] = probs.max().item()\n",
    "        \n",
    "    df_val.prediction = df_val.prediction.astype(int)\n",
    "    return df_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b0a033b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-09T02:42:54.668782Z",
     "iopub.status.busy": "2023-08-09T02:42:54.668631Z",
     "iopub.status.idle": "2023-08-09T03:05:16.365241Z",
     "shell.execute_reply": "2023-08-09T03:05:16.364900Z"
    },
    "papermill": {
     "duration": 1341.700675,
     "end_time": "2023-08-09T03:05:16.366200",
     "exception": false,
     "start_time": "2023-08-09T02:42:54.665525",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#papermill_description=RUNNING_INFERENCE\n",
    "pd_dataset = dataset.to_pandas()\n",
    "if max_samples > 0 and max_samples < len(pd_dataset):\n",
    "    pd_dataset = pd_dataset.iloc[:max_samples - 1]\n",
    "df2 = glue_inference(pd_dataset, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d101bc7",
   "metadata": {
    "papermill": {
     "duration": 0.002477,
     "end_time": "2023-08-09T03:05:16.371337",
     "exception": false,
     "start_time": "2023-08-09T03:05:16.368860",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 5 - Evaluate performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4c6143e7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-09T03:05:16.377042Z",
     "iopub.status.busy": "2023-08-09T03:05:16.376918Z",
     "iopub.status.idle": "2023-08-09T03:05:17.127775Z",
     "shell.execute_reply": "2023-08-09T03:05:17.127446Z"
    },
    "papermill": {
     "duration": 0.754842,
     "end_time": "2023-08-09T03:05:17.128667",
     "exception": false,
     "start_time": "2023-08-09T03:05:16.373825",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class prob > 0.0: {'accuracy': 0.3369332654100866}\n",
      "Class prob > 0.1: {'accuracy': 0.3369332654100866}\n",
      "Class prob > 0.2: {'accuracy': 0.3369332654100866}\n",
      "Class prob > 0.3: {'accuracy': 0.3369332654100866}\n",
      "Class prob > 0.4: {'accuracy': 0.3373863288035149}\n",
      "Class prob > 0.5: {'accuracy': 0.3395170483987978}\n",
      "Class prob > 0.6: {'accuracy': 0.34331698998081434}\n",
      "Class prob > 0.7: {'accuracy': 0.34748010610079577}\n",
      "Class prob > 0.8: {'accuracy': 0.35404742436631237}\n",
      "Class prob > 0.9: {'accuracy': 0.36727703859834016}\n"
     ]
    }
   ],
   "source": [
    "#papermill_description=EVALUATION\n",
    "glue_metric = load(\"glue\", \"mnli_matched\")\n",
    "\n",
    "for precision in np.linspace(0,1,10, endpoint=False):\n",
    "    df_filt = df2[df2.prob > precision]\n",
    "    \n",
    "    predictions = df_filt['prediction'].to_list()\n",
    "    answers = df_filt['label'].to_list()\n",
    "\n",
    "    results = glue_metric.compute(predictions=predictions, references=answers)\n",
    "    print(f'Class prob > {precision:.1f}: {results}')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a4240841",
   "metadata": {
    "papermill": {
     "duration": 0.002573,
     "end_time": "2023-08-09T03:05:17.133809",
     "exception": false,
     "start_time": "2023-08-09T03:05:17.131236",
     "status": "completed"
    },
    "tags": []
   },
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1349.163109,
   "end_time": "2023-08-09T03:05:17.652301",
   "environment_variables": {},
   "exception": null,
   "input_path": "06_glue.ipynb",
   "output_path": "outputs/06_glue_int4.ipynb",
   "parameters": {
    "max_samples": -1,
    "model_size": "int4"
   },
   "start_time": "2023-08-09T02:42:48.489192",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}